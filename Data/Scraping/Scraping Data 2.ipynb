{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping data from transport and logistics website 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps : \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1- Get companies links\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "2- Get data using those links "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install tools and libraries\n",
    "\n",
    "from selenium import webdriver as wd\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.wait import WebDriverWait\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests as rq\n",
    "import bs4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to get links\n",
    "\n",
    "browser = wd.Firefox(executable_path=r'C:\\Users\\USER\\geckodriver.exe')\n",
    "browser.get(\"https://www.website2.ma/maroc\")\n",
    "\n",
    "quoiqui = WebDriverWait(browser,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"input[name='string']\")))\n",
    "quoiqui.send_keys(\"transport\")\n",
    "\n",
    "trouver = WebDriverWait(browser,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"button.hidden-xs:nth-child(2)\")))\n",
    "trouver.click()\n",
    "\n",
    "listLink = []\n",
    "\n",
    "try:\n",
    "    links = browser.find_elements_by_class_name(\"moodalbox\")\n",
    "    for link in links:\n",
    "        listLink.append(link.get_attribute('href'))\n",
    "    \n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep unique links\n",
    "\n",
    "newListLink = []\n",
    "for l in listLink:\n",
    "    if l not in newListLink:\n",
    "        newListLink.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store links in a file (text, csv, excel...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Script to get data from links\n",
    "\n",
    "\n",
    "Activite1 = []\n",
    "Logo = []\n",
    "Nom = []\n",
    "Tel = []\n",
    "Adress = []\n",
    "Description = []\n",
    "Activite2 = []\n",
    "Site = []\n",
    "\n",
    "i=0\n",
    "\n",
    "\n",
    "for link in newListLinks:\n",
    "    try:\n",
    "        res = rq.get(link)\n",
    "        soup = bs4.BeautifulSoup(res.text, 'html.parser')\n",
    "        \n",
    "        adresse = soup.select(\".col-xs-8 > div:nth-child(2)\")\n",
    "        if adresse[0].text == \"\":\n",
    "            Adress.append(\" \")\n",
    "        else:\n",
    "            Adress.append(adresse[0].text)\n",
    "\n",
    "        nom = soup.select(\"#lenom\")\n",
    "        if nom[0].text == \"\":\n",
    "            Nom.append(\" \")\n",
    "        else:\n",
    "            Nom.append(nom[0].text)\n",
    "            print(nom[0].text)\n",
    "            \n",
    "        tel = soup.select(\".letel > a:nth-child(2)\")\n",
    "        if tel[0].text == \"\":\n",
    "            Tel.append(\" \")\n",
    "        else:\n",
    "            Tel.append(tel[0].text)\n",
    "            \n",
    "        description = soup.select(\"#presentation_annonceur_id > div:nth-child(1) > div:nth-child(1) > div:nth-child(2) > p:nth-child(1)\")\n",
    "        if description[0].text == \"\":\n",
    "            Description.append(\" \")\n",
    "        else:\n",
    "            Description.append(description[0].text)\n",
    "            \n",
    "        activite2 = soup.select(\"div.panel:nth-child(2) > div:nth-child(2)\")\n",
    "        if activite2[0].text == \"\":\n",
    "            Activite2.append(\" \")\n",
    "        else:\n",
    "            Activite2.append(activite2[0].text)\n",
    "                               \n",
    "        activite1 = soup.select(\".pull-left > div:nth-child(1) > span:nth-child(1) > a:nth-child(1) > span:nth-child(1)\")\n",
    "        if activite1[0].text == \"\":\n",
    "            Activite1.append(\" \")\n",
    "        else:\n",
    "            Activite1.append(activite1[0].text)\n",
    "\n",
    "        \n",
    "        site = soup.find_all(\"a\", id=\"stweb-1\")\n",
    "        for link in site:\n",
    "            l = link.get('href')\n",
    "            break;\n",
    "        if l == \"\":\n",
    "            Site.append(\" \")\n",
    "        else:\n",
    "            Site.append(l)\n",
    "    \n",
    "        images = soup.find_all(\"img\", alt=True)\n",
    "        for pic in images:\n",
    "            if pic.get('src').find(\"https://www.website2.ma/pubs\") != -1: # images url contains website name\n",
    "                p = pic.get('src')\n",
    "                break;\n",
    "        if p == \"\":\n",
    "            Logo.append(\" \")\n",
    "        else:\n",
    "            Logo.append(p)\n",
    "            \n",
    "        i=i+1\n",
    "    \n",
    "    except Exception as e1:\n",
    "        print(e1)\n",
    "        try:\n",
    "\n",
    "                adresse = soup.select(\"#her_we_go > div:nth-child(2) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(1) > div:nth-child(2)\")\n",
    "                if adresse[0].text == \"\":\n",
    "                    Adress.append(\" \")\n",
    "                else:\n",
    "                    Adress.append(adresse[0].text)\n",
    "                \n",
    "                \n",
    "                nom = soup.select(\"#lenom\")\n",
    "                if nom[0].text == \"\":\n",
    "                    Nom.append(\" \")\n",
    "                else:\n",
    "                    Nom.append(nom[0].text)\n",
    "                    print(nom[0].text)\n",
    "                  \n",
    "                tel = soup.select(\".letel > a:nth-child(2)\")\n",
    "                if tel[0].text == \"\":\n",
    "                    Tel.append(\" \")\n",
    "                else:\n",
    "                    Tel.append(tel[0].text)\n",
    "            \n",
    "                activite1 = soup.select(\".pull-left > div:nth-child(1) > span:nth-child(1) > a:nth-child(1) > span:nth-child(1)\")\n",
    "                if activite1[0].text == \"\":\n",
    "                    Activite1.append(\" \")\n",
    "                else:\n",
    "                    Activite1.append(activite1[0].text)\n",
    "                \n",
    "                Site.append(\" \")\n",
    "                Logo.append(\" \")\n",
    "                Description.append(\" \")\n",
    "                Activite2.append(\" \")\n",
    "                \n",
    "        except Exception as e2:\n",
    "            print(e2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store Data in a file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
